{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitcondad36d02735c7842b49397084c546dac98",
   "display_name": "Python 3.7.4 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.feature_selection\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "npf_train = pd.read_csv(\"data/npf_train.csv\")\n",
    "npf_test = pd.read_csv(\"data/npf_test_hidden.csv\")"
   ]
  },
  {
   "source": [
    "The function below is just for preprosessing the data. It drops date,id,partlybad columns and std's"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprosessing(npf,scaler):\n",
    "    '''Preprosessing function for npf_*.csv files'''\n",
    "\n",
    "    # Dropping features 'partlybad','id' and 'date' because we won't need them. Feature 'partlybad' was only False \n",
    "    X = npf.drop(['date','id','partlybad','class4'],axis=1)\n",
    "    \n",
    "\n",
    "    #Dropping std's\n",
    "    X_means = X.drop([c for c in npf.columns if 'std' in c],axis=1)\n",
    "\n",
    "    X_means['class4'] = npf['class4']\n",
    "    return X_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_feature_columns(X_train, y_train, n):\n",
    "    '''Return n best feature columns'''\n",
    "    select = sklearn.feature_selection.SelectKBest(k=n)\n",
    "    selected_features = select.fit(X_train, y_train)\n",
    "    indices_selected = selected_features.get_support(indices=True)\n",
    "    colnames_selected = [X_train.columns[i] for i in indices_selected]\n",
    "\n",
    "    return colnames_selected"
   ]
  },
  {
   "source": [
    "Loading the data and doing some preprosessing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "npf = preprosessing(npf_train,scale)\n",
    "X_npf = npf.drop('class4',axis=1)\n",
    "#y = npf['class4']\n",
    "\n",
    "# Changing the categorical values to integers\n",
    "y = npf['class4'].astype('category').cat.codes"
   ]
  },
  {
   "source": [
    "Scaling the data for zero mean and unit variance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Removing .means from all column names\n",
    "    cols = [col[:-5] for col in X_npf.columns]\n",
    "\n",
    "    # Normalizing for zero mean and unit variance\n",
    "    X_np = scale(X_npf)\n",
    "\n",
    "    X = pd.DataFrame(X_np, columns=cols)"
   ]
  },
  {
   "source": [
    "Selecting 20 best features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = best_feature_columns(X,y,20)\n",
    "#features = X.columns"
   ]
  },
  {
   "source": [
    "Now doing the clustering. Fist using K-Means clustering. We set 4 clusters as parameter because we know that we have 4 classes to distinguish"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=4, n_init=50, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=3, tol=0.0001, verbose=0)"
      ]
     },
     "metadata": {},
     "execution_count": 352
    }
   ],
   "source": [
    "kmeans_cluster = KMeans(4,n_init=50,random_state=3)\n",
    "kmeans_cluster.fit(X)\n",
    "#kmeans_cluster = KMeans(n_clusters=4, n_init=50,random_state=42).fit(X[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.16279069767441862"
      ]
     },
     "metadata": {},
     "execution_count": 353
    }
   ],
   "source": [
    "acc = accuracy_score(y, kmeans_cluster.labels_)\n",
    "acc"
   ]
  },
  {
   "source": [
    "Hmm quite bad accuracy. The labels are probably permuted. Function find_permutation find the right permutation to assing the correct labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def find_permutation(n_clusters, real_labels, labels):\n",
    "    permutation = []\n",
    "    for i in range(n_clusters):\n",
    "        idx = labels == i\n",
    "        new_label=scipy.stats.mode(real_labels[idx])[0][0]  # Choose the most common label among data points in the cluster\n",
    "        permutation.append(new_label)\n",
    "    return permutation"
   ]
  },
  {
   "source": [
    "So here is the correct permutation for the cluster labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "permutation = find_permutation(4,y,kmeans_cluster.labels_)\n",
    "print(permutation)"
   ]
  },
  {
   "source": [
    "Frankly it distinguishes only labels 0 and 3  \n",
    "0 = II  \n",
    "1 = Ia  \n",
    "2 = Ib  \n",
    "3 = nonevent\n",
    "\n",
    "Checking how the clustering events are distributed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys([3, 2, 0, 1])\ndict_values([215, 83, 106, 26])\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y).keys())\n",
    "print(Counter(y).values())\n"
   ]
  },
  {
   "source": [
    "Okay so event and nonevents are evenly distribute 215 / 215 = 50/50  \n",
    "0 = II = 24.7 %  \n",
    "1 = Ia = 06.0 %  \n",
    "2 = Ib = 19.3 %  \n",
    "3 = nonevent = 50.0 %\n",
    "\n",
    "But anyways now we have the new accuracy score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is 0.6069767441860465\n"
     ]
    }
   ],
   "source": [
    "new_labels = [ permutation[label] for label in kmeans_cluster.labels_]   # permute the labels\n",
    "print(\"Accuracy score is\", accuracy_score(y, new_labels))\n"
   ]
  },
  {
   "source": [
    "Okay so this is already a lot better. Let's do a confusion matrix to double check the results\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Clusters   0    1   2  3\n",
       "Labels                  \n",
       "0         35   13  58  0\n",
       "1          3    7  16  0\n",
       "2         22    6  55  0\n",
       "3         89  111  12  3"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Clusters</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n    <tr>\n      <th>Labels</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>35</td>\n      <td>13</td>\n      <td>58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>22</td>\n      <td>6</td>\n      <td>55</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>89</td>\n      <td>111</td>\n      <td>12</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 345
    }
   ],
   "source": [
    "df = pd.DataFrame({'Labels': y, 'Clusters':kmeans_cluster.labels_})\n",
    "ct = pd.crosstab(df['Labels'],df['Clusters'])\n",
    "ct"
   ]
  },
  {
   "source": [
    "I'm not getting much out of this confusion matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.41      0.55      0.47       106\n           1       0.00      0.00      0.00        26\n           2       0.00      0.00      0.00        83\n           3       0.70      0.94      0.81       215\n\n    accuracy                           0.61       430\n   macro avg       0.28      0.37      0.32       430\nweighted avg       0.45      0.61      0.52       430\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y,new_labels))"
   ]
  },
  {
   "source": [
    "Even the classification report doesn't promise good results. Maybe trying different scaling or not scaling at all would help. Let's try MinMax, Standard and no scaling at all"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_minmax = pd.DataFrame(MinMaxScaler().fit_transform(X_npf), columns=X_npf.columns)\n",
    "X_standard = pd.DataFrame(StandardScaler().fit_transform(X_npf), columns=X_npf.columns)\n",
    "X_noscaling = X_npf"
   ]
  },
  {
   "source": [
    "Feature selection for different scalers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_features = best_feature_columns(X_minmax,y,20)\n",
    "standard_features = best_feature_columns(X_standard,y,20)\n",
    "noscaling_features = best_feature_columns(X_noscaling,y,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for MinMax scaling 0.5651162790697675\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0, 0, 3, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 357
    }
   ],
   "source": [
    "# Minmax scaling result\n",
    "\n",
    "cluster = KMeans(4,n_init=50,random_state=42)\n",
    "minmax_cluster = cluster.fit(X_minmax[minmax_features])\n",
    "permutation = find_permutation(4,y,minmax_cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in minmax_cluster.labels_] \n",
    "print(\"Accuracy score is for MinMax scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for Standard scaling 0.586046511627907\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[2, 3, 0, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 358
    }
   ],
   "source": [
    "# Standard scaling result\n",
    "\n",
    "cluster = KMeans(4,n_init=50,random_state=42)\n",
    "stamdard_cluster = cluster.fit(X_standard[standard_features])\n",
    "permutation = find_permutation(4,y,stamdard_cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in stamdard_cluster.labels_] \n",
    "print(\"Accuracy score is for Standard scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for no scaling 0.5790697674418605\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[2, 3, 0, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 359
    }
   ],
   "source": [
    "# No scaling result\n",
    "\n",
    "cluster = KMeans(4,n_init=50,random_state=42)\n",
    "nofeatures_cluster = cluster.fit(X_noscaling[noscaling_features])\n",
    "permutation = find_permutation(4,y,nofeatures_cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in nofeatures_cluster.labels_] \n",
    "print(\"Accuracy score is for no scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "source": [
    "Well this is kind of odd? Class Ia is totally missing from the results? Let's try hieragical clustering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for no scaling 0.5720930232558139\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3, 2, 3, 0]"
      ]
     },
     "metadata": {},
     "execution_count": 306
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Zero mean and unit variance scaling\n",
    "cluster = AgglomerativeClustering(n_clusters=4, affinity='euclidean',linkage='ward')\n",
    "data = X[features].values\n",
    "cluster.fit(data)\n",
    "permutation = find_permutation(4,y,cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in cluster.labels_] \n",
    "print(\"Accuracy score is for no scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "source": [
    "Trying the different scalers here too (MinMax, Standard and no scaling)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for no scaling 0.586046511627907\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3, 0, 0, 2]"
      ]
     },
     "metadata": {},
     "execution_count": 307
    }
   ],
   "source": [
    "# Minmax scaling\n",
    "cluster = AgglomerativeClustering(n_clusters=4, affinity='euclidean',linkage='ward')\n",
    "data = X_minmax[minmax_features].values\n",
    "cluster.fit(data)\n",
    "permutation = find_permutation(4,y,cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in cluster.labels_] \n",
    "print(\"Accuracy score is for minmax scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for no scaling 0.5720930232558139\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3, 2, 3, 0]"
      ]
     },
     "metadata": {},
     "execution_count": 308
    }
   ],
   "source": [
    "# Standard scaling\n",
    "cluster = AgglomerativeClustering(n_clusters=4, affinity='euclidean',linkage='ward')\n",
    "data = X_standard[standard_features].values\n",
    "cluster.fit(data)\n",
    "permutation = find_permutation(4,y,cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in cluster.labels_] \n",
    "print(\"Accuracy score is for standard scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for no scaling 0.5767441860465117\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3, 2, 3, 0]"
      ]
     },
     "metadata": {},
     "execution_count": 309
    }
   ],
   "source": [
    "# No scaling\n",
    "cluster = AgglomerativeClustering(n_clusters=4, affinity='euclidean',linkage='ward')\n",
    "data = X_noscaling[noscaling_features].values\n",
    "cluster.fit(data)\n",
    "permutation = find_permutation(4,y,cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in cluster.labels_] \n",
    "print(\"Accuracy score is for no scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "source": [
    "The accurasy seems stuck in around 0.57. Maybe it is just that it can't be predicted so well. I'd go with the k-means clustering. \n",
    "\n",
    "Last, let's try different amount of features with k-means clustering. I will use StandardScaler as it got the best accuracy with most classes present. The following cell was to help trying to find the optimal amount of features with sklearns selectKBest() function. The cell returns the parameters from best accuracy score and prints the features that the model used"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best accuracy score is for 18 features with acc of: 0.586046511627907 the permutation being [2, 3, 0, 3]\n['Glob.mean', 'NET.mean', 'PAR.mean', 'RGlob.mean', 'RHIRGA168.mean', 'RHIRGA336.mean', 'RHIRGA42.mean', 'RHIRGA504.mean', 'RHIRGA672.mean', 'RHIRGA84.mean', 'UV_A.mean', 'UV_B.mean']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.586046511627907"
      ]
     },
     "metadata": {},
     "execution_count": 404
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "best_score = 0\n",
    "best_permu = []\n",
    "n_features = 0\n",
    "best_features = []\n",
    "for i in range(1,len(X_noscaling.columns)):\n",
    "    standard_features = best_feature_columns(X_standard,y,i)\n",
    "    cluster = KMeans(4,n_init=50,random_state=42)\n",
    "    standard_cluster = cluster.fit(X_standard[standard_features])\n",
    "    permutation = find_permutation(4,y,standard_cluster.labels_)\n",
    "    new_labels = [ permutation[label] for label in stamdard_cluster.labels_] \n",
    "    acc = accuracy_score(y, new_labels)\n",
    "\n",
    "    if (acc > best_score):\n",
    "        best_score = acc\n",
    "        best_permu = permutation\n",
    "        n_features = i\n",
    "        best_features = standard_features\n",
    "\n",
    "print(\"Best accuracy score is for {} features with acc of: {} the permutation being {}\".format(n_features, best_score,best_permu))\n",
    "print(best_features)"
   ]
  },
  {
   "source": [
    "I tried here to find a model which gets the best accuracy with 12 features as Lauri said that he used the same number of features. Didn't get any better result as is was still stuck to 0.58"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ccuracy score is for 12 features with acc of: 0.586046511627907 the permutation being [2, 3, 0, 3]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Glob.mean',\n",
       " 'NET.mean',\n",
       " 'PAR.mean',\n",
       " 'RGlob.mean',\n",
       " 'RHIRGA168.mean',\n",
       " 'RHIRGA336.mean',\n",
       " 'RHIRGA42.mean',\n",
       " 'RHIRGA504.mean',\n",
       " 'RHIRGA672.mean',\n",
       " 'RHIRGA84.mean',\n",
       " 'UV_A.mean',\n",
       " 'UV_B.mean']"
      ]
     },
     "metadata": {},
     "execution_count": 405
    }
   ],
   "source": [
    "n_features = 12\n",
    "standard_features = best_feature_columns(X_standard,y,n_features)\n",
    "cluster = KMeans(4,n_init=50,random_state=18)\n",
    "standard_cluster = cluster.fit(X_standard[standard_features])\n",
    "permutation = find_permutation(4,y,standard_cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in stamdard_cluster.labels_] \n",
    "acc = accuracy_score(y, new_labels)\n",
    "print(\"ccuracy score is for {} features with acc of: {} the permutation being {}\".format(n_features, acc,permutation))\n",
    "standard_features"
   ]
  },
  {
   "source": [
    "# Now trying the supervised learning methods  \n",
    "\n",
    "First logistic regression\n",
    "\n",
    "Train and test sets are divided in 75/25 proportions automatically"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.71\nAccuracy of Logistic regression classifier on test set: 0.70\n"
     ]
    }
   ],
   "source": [
    "# X being X_standard which is just standard scaled X values\n",
    "y = npf['class4']\n",
    "\n",
    "# Splitting the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standard, y, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "source": [
    "Trying the same with best 12 features. The features below were the best features which were given from the selectKBest() function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Glob.mean',\n",
    " 'NET.mean',\n",
    " 'PAR.mean',\n",
    " 'RGlob.mean',\n",
    " 'RHIRGA168.mean',\n",
    " 'RHIRGA336.mean',\n",
    " 'RHIRGA42.mean',\n",
    " 'RHIRGA504.mean',\n",
    " 'RHIRGA672.mean',\n",
    " 'RHIRGA84.mean',\n",
    " 'UV_A.mean',\n",
    " 'UV_B.mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.62\nAccuracy of Logistic regression classifier on test set: 0.66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standard[features], y, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "source": [
    "Oh, worse score. Maybe well just include all features. Let's try Decission Tree next"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 1.00\nAccuracy of Decision Tree classifier on test set: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Decission tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standard, y, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.75\nAccuracy of K-NN classifier on test set: 0.67\n"
     ]
    }
   ],
   "source": [
    "# K neighbour classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of LDA classifier on training set: 0.76\nAccuracy of LDA classifier on test set: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "print('Accuracy of LDA classifier on training set: {:.2f}'\n",
    "     .format(lda.score(X_train, y_train)))\n",
    "print('Accuracy of LDA classifier on test set: {:.2f}'\n",
    "     .format(lda.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of GNB classifier on training set: 0.56\nAccuracy of GNB classifier on test set: 0.55\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "print('Accuracy of GNB classifier on training set: {:.2f}'\n",
    "     .format(gnb.score(X_train, y_train)))\n",
    "print('Accuracy of GNB classifier on test set: {:.2f}'\n",
    "     .format(gnb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of SVM classifier on training set: 0.73\nAccuracy of SVM classifier on test set: 0.70\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "source": [
    "# SVM and logistic regression gave the best accuracies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[17  0  1  5]\n [ 3  0  0  1]\n [13  3  5  4]\n [ 1  0  1 54]]\n              precision    recall  f1-score   support\n\n          II       0.50      0.74      0.60        23\n          Ia       0.00      0.00      0.00         4\n          Ib       0.71      0.20      0.31        25\n    nonevent       0.84      0.96      0.90        56\n\n    accuracy                           0.70       108\n   macro avg       0.51      0.48      0.45       108\nweighted avg       0.71      0.70      0.67       108\n\n"
     ]
    }
   ],
   "source": [
    "# This scores are for logreg\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred = logreg.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[15  0  4  4]\n [ 2  0  0  2]\n [16  0  6  3]\n [ 1  0  0 55]]\n              precision    recall  f1-score   support\n\n          II       0.44      0.65      0.53        23\n          Ia       0.00      0.00      0.00         4\n          Ib       0.60      0.24      0.34        25\n    nonevent       0.86      0.98      0.92        56\n\n    accuracy                           0.70       108\n   macro avg       0.48      0.47      0.45       108\nweighted avg       0.68      0.70      0.67       108\n\n"
     ]
    }
   ],
   "source": [
    "# This scores are for SVM\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "source": [
    "# Thought process\n",
    "\n",
    "Data preprocessing  \n",
    "    - Dropped std's  \n",
    "    - Used various different scaling types to see if there is a difference\n",
    "\n",
    "In every machine learning method 4 clusters was selected as paremeter because we know that we have 4 different event to distinguish\n",
    "\n",
    "## Unsupervised learning methods  \n",
    "\n",
    "    - K-means  \n",
    "        * Changed categorical labels to integers  \n",
    "        * Scaled data to zero mean and unit variance\n",
    "        * Selected 20 best feature with skleanr selectKBest()  \n",
    "        * Score after permutation was 0.60, but only events of II and nonevent was distinguished  \n",
    "        * Next I tried to do the same with different scaling methods  \n",
    "            - MinMaxScaler, StandardScaler and no scaling at all  \n",
    "        MinMax:     acc = 0.565  \n",
    "        Standard:   acc = 0.586\n",
    "        NoScaling:  acc = 0.576  \n",
    "\n",
    "    - Hierachical clustering  \n",
    "        * I performed the same test with AgglomerativeClustering to see if this unsupervised method performs better\n",
    "\n",
    "        Scale:      acc = 0.572\n",
    "        MinMax:     acc = 0.586\n",
    "        Standard:   acc = 0.572\n",
    "        NoScaling:  acc = 0.576\n",
    "\n",
    "        * So no development here\n",
    "        * Lastly I tried k-means with StandardScaler, as it had the best accuracy while most of the classes were present, and different amount of features.  \n",
    "\n",
    "        There was no clear trend but with the binay classifier 12 features were the best to I tried it also and the result was not significantly better.  \n",
    "\n",
    "\n",
    "## Supervised learning methods\n",
    "\n",
    "Same preprosessing of the data except I didn't categorizise the labels and used only Standard scaler. Tested just a bunch of different supervised learning methods. Started with Logistic regression  \n",
    "\n",
    "    - Logistic regression  \n",
    "        * Data splitted in 75/25 ratio to train and test\n",
    "        * Acc score = 0.70 on test set\n",
    "        * Tried to reduce the amount of features to 12 best but it lowered the accuracy  \n",
    "            - Acc score = 0.66 (12 features)\n",
    "        * Decided to keep all the features along\n",
    "    - Next just test different methods (all acc scores on test set)\n",
    "\n",
    "        Decission there                 acc = 0.64\n",
    "        K-NN                            acc = 0.67\n",
    "        Linear discriminant analysis    acc = 0.64\n",
    "        Gaussia NB                      acc = 0.55\n",
    "        SVM                             acc = 0.70  \n",
    "\n",
    "    - LogReg and SVM turned out to be the best from all supervised and unsupervised learning methods, but I chose LogReg to be the best. That is because it's weighted average and the recall values turned out to be a little better than SVM's\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}