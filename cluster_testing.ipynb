{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitcondad36d02735c7842b49397084c546dac98",
   "display_name": "Python 3.7.4 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.feature_selection\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "npf_train = pd.read_csv(\"data/npf_train.csv\")\n",
    "npf_test = pd.read_csv(\"data/npf_test_hidden.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprosessing(npf,scaler):\n",
    "    '''Preprosessing function for npf_*.csv files'''\n",
    "\n",
    "    # Dropping features 'partlybad','id' and 'date' because we won't need them. Feature 'partlybad' was only False \n",
    "    X = npf.drop(['date','id','partlybad','class4'],axis=1)\n",
    "    \n",
    "\n",
    "    #Dropping std's\n",
    "    X_means = X.drop([c for c in npf.columns if 'std' in c],axis=1)\n",
    "\n",
    "\n",
    "    # Removing .means from all column names\n",
    "    cols = [col[:-5] for col in X_means.columns]\n",
    "\n",
    "    # Normalizing for zero mean and unit variance\n",
    "    X_means_np = scaler(X_means)\n",
    "\n",
    "    #df = pd.DataFrame(X_means_np, columns=cols)\n",
    "    #df[\"class4\"] = npf[\"class4\"]\n",
    "\n",
    "    #return df\n",
    "    X_means['class4'] = npf['class4']\n",
    "    return X_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_feature_columns(X_train, y_train, n):\n",
    "    '''Return n best feature columns'''\n",
    "    select = sklearn.feature_selection.SelectKBest(k=n)\n",
    "    selected_features = select.fit(X_train, y_train)\n",
    "    indices_selected = selected_features.get_support(indices=True)\n",
    "    colnames_selected = [X_train.columns[i] for i in indices_selected]\n",
    "\n",
    "    return colnames_selected"
   ]
  },
  {
   "source": [
    "Loading the data and doing some preprosessing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "npf = preprosessing(npf_train,scale)\n",
    "X_npf = npf.drop('class4',axis=1)\n",
    "#y1 = npf['class4']\n",
    "\n",
    "# Changing the categorical values to integers\n",
    "y = npf['class4'].astype('category').cat.codes"
   ]
  },
  {
   "source": [
    "Scaling the data for zero mean and unit variance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Removing .means from all column names\n",
    "    cols = [col[:-5] for col in X_npf.columns]\n",
    "\n",
    "    # Normalizing for zero mean and unit variance\n",
    "    X_np = scale(X_npf)\n",
    "\n",
    "    X = pd.DataFrame(X_np, columns=cols)"
   ]
  },
  {
   "source": [
    "Selecting 20 best features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = best_feature_columns(X,y,20)\n",
    "#features = X.columns"
   ]
  },
  {
   "source": [
    "Now doing the clustering. Fist using K-Means clustering. We set 4 clusters as parameter because we know that we have 4 classes to distinguish"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=4, n_init=50, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=42, tol=0.0001, verbose=0)"
      ]
     },
     "metadata": {},
     "execution_count": 224
    }
   ],
   "source": [
    "kmeans_cluster = KMeans(4,n_init=50,random_state=42)\n",
    "kmeans_cluster.fit(X)\n",
    "#kmeans_cluster = KMeans(n_clusters=4, n_init=50,random_state=42).fit(X[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.23255813953488372"
      ]
     },
     "metadata": {},
     "execution_count": 225
    }
   ],
   "source": [
    "acc = accuracy_score(y, kmeans_cluster.labels_)\n",
    "acc"
   ]
  },
  {
   "source": [
    "Hmm quite bad accuracy. The labels are probably permuted"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def find_permutation(n_clusters, real_labels, labels):\n",
    "    permutation = []\n",
    "    for i in range(n_clusters):\n",
    "        idx = labels == i\n",
    "        new_label=scipy.stats.mode(real_labels[idx])[0][0]  # Choose the most common label among data points in the cluster\n",
    "        permutation.append(new_label)\n",
    "    return permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[3, 3, 0, 3]\n"
     ]
    }
   ],
   "source": [
    "permutation = find_permutation(4,y,kmeans_cluster.labels_)\n",
    "print(permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys([3, 2, 0, 1])\ndict_values([215, 83, 106, 26])\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y).keys())\n",
    "print(Counter(y).values())\n"
   ]
  },
  {
   "source": [
    "Hmm why it misses value 1?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is 0.6069767441860465\n"
     ]
    }
   ],
   "source": [
    "new_labels = [ permutation[label] for label in kmeans_cluster.labels_]   # permute the labels\n",
    "print(\"Accuracy score is\", accuracy_score(y, new_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.41      0.55      0.47       106\n           1       0.00      0.00      0.00        26\n           2       0.00      0.00      0.00        83\n           3       0.70      0.94      0.81       215\n\n    accuracy                           0.61       430\n   macro avg       0.28      0.37      0.32       430\nweighted avg       0.45      0.61      0.52       430\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y,new_labels))"
   ]
  },
  {
   "source": [
    "Maybe trying different scaling or not scaling at all would help"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_minmax = pd.DataFrame(MinMaxScaler().fit_transform(X_npf), columns=X_npf.columns)\n",
    "X_standard = pd.DataFrame(StandardScaler().fit_transform(X_npf), columns=X_npf.columns)\n",
    "X_noscaling = X_npf"
   ]
  },
  {
   "source": [
    "Feature selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_features = best_feature_columns(X_minmax,y,20)\n",
    "standard_features = best_feature_columns(X_standard,y,20)\n",
    "noscaling_features = best_feature_columns(X_noscaling,y,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for MinMax scaling 0.5651162790697675\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0, 0, 3, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 265
    }
   ],
   "source": [
    "# Minmax scaling result\n",
    "\n",
    "cluster = KMeans(4,n_init=50,random_state=42)\n",
    "minmax_cluster = cluster.fit(X_minmax[minmax_features])\n",
    "permutation = find_permutation(4,y,minmax_cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in minmax_cluster.labels_] \n",
    "print(\"Accuracy score is for MinMax scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for Standard scaling 0.586046511627907\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[2, 3, 0, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 266
    }
   ],
   "source": [
    "# Standard scaling result\n",
    "\n",
    "cluster = KMeans(4,n_init=50,random_state=42)\n",
    "stamdard_cluster = cluster.fit(X_standard[standard_features])\n",
    "permutation = find_permutation(4,y,stamdard_cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in stamdard_cluster.labels_] \n",
    "print(\"Accuracy score is for Standard scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for no scaling 0.5790697674418605\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[2, 3, 0, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 267
    }
   ],
   "source": [
    "# No scaling result\n",
    "\n",
    "cluster = KMeans(4,n_init=50,random_state=42)\n",
    "nofeatures_cluster = cluster.fit(X_noscaling[noscaling_features])\n",
    "permutation = find_permutation(4,y,nofeatures_cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in nofeatures_cluster.labels_] \n",
    "print(\"Accuracy score is for no scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "source": [
    "Well this is kind of odd? Class Ia is totally missing from the results? Let's try hieragical clustering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for no scaling 0.5720930232558139\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3, 2, 3, 0]"
      ]
     },
     "metadata": {},
     "execution_count": 306
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Zero mean and unit variance scaling\n",
    "cluster = AgglomerativeClustering(n_clusters=4, affinity='euclidean',linkage='ward')\n",
    "data = X[features].values\n",
    "cluster.fit(data)\n",
    "permutation = find_permutation(4,y,cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in cluster.labels_] \n",
    "print(\"Accuracy score is for no scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for no scaling 0.586046511627907\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3, 0, 0, 2]"
      ]
     },
     "metadata": {},
     "execution_count": 307
    }
   ],
   "source": [
    "# Minmax scaling\n",
    "cluster = AgglomerativeClustering(n_clusters=4, affinity='euclidean',linkage='ward')\n",
    "data = X_minmax[minmax_features].values\n",
    "cluster.fit(data)\n",
    "permutation = find_permutation(4,y,cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in cluster.labels_] \n",
    "print(\"Accuracy score is for no scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for no scaling 0.5720930232558139\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3, 2, 3, 0]"
      ]
     },
     "metadata": {},
     "execution_count": 308
    }
   ],
   "source": [
    "# Standard scaling\n",
    "cluster = AgglomerativeClustering(n_clusters=4, affinity='euclidean',linkage='ward')\n",
    "data = X_standard[standard_features].values\n",
    "cluster.fit(data)\n",
    "permutation = find_permutation(4,y,cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in cluster.labels_] \n",
    "print(\"Accuracy score is for no scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score is for no scaling 0.5767441860465117\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3, 2, 3, 0]"
      ]
     },
     "metadata": {},
     "execution_count": 309
    }
   ],
   "source": [
    "# No scaling\n",
    "cluster = AgglomerativeClustering(n_clusters=4, affinity='euclidean',linkage='ward')\n",
    "data = X_noscaling[noscaling_features].values\n",
    "cluster.fit(data)\n",
    "permutation = find_permutation(4,y,cluster.labels_)\n",
    "new_labels = [ permutation[label] for label in cluster.labels_] \n",
    "print(\"Accuracy score is for no scaling\", accuracy_score(y, new_labels))\n",
    "permutation"
   ]
  },
  {
   "source": [
    "Maybe it is just that it can't be predicted so well. I'd go with the k-means clustering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}